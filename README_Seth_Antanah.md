# Data Pipeline Engineering

## Task

Design an advance data pipeline that simulates real-world data (ingestion) for an e-commerce platform.

The pipeline must support and be able to handle

* Data schema evolution
* Incremental updates
* Handling various file formats

### Goals

Design a data pipeline that is:

* Scalable
* Fault-tolerant
* Efficient processing 

## My Data Ingestion Process

### Discovery

Six data sources have been identified.
The data sources includes:
* two JSON files with customer data informationm for market 1 and 2
* four CSV files with information on delivery and orders information for market 1 and 2

The datasets are located in the local project file system.

### Data Aquisition

- **Functionality:** Does the data pipeline process and store data accurately?
- **Scalability:** Is the solution scalable to handle larger datasets and increased processing loads?
- **Fault Tolerance:** How well does the pipeline handle errors and failures during processing?
- **Documentation:** Is the `README_YOUR_NAME.md` comprehensive and easy to follow?
- **Code Quality:** Is the code well-organized, readable, and maintainable?


